% ============================================================================
% Section 7: Agent-Ready Political Infrastructure Design
% ============================================================================

\section{エージェントレディな政治インフラの設計原則}
\label{sec:agent-ready-design}

AIエージェント——大規模言語モデル（LLM）に基づく自律的な行動主体——の能力が急速に拡大する中、政治プロセスへのエージェントの参入は、もはや遠い未来の問題ではなく、数年以内に現実化する設計課題である。本節では、エージェントの政治プロセスへの参入の現状と展望を分析した上で、エージェントレディな政治インフラの設計原則を導出し、OJPPにおける実装を示す。

% ----------------------------------------------------------------------------
\subsection{AIエージェントの政治プロセスへの参入}
\label{subsec:agent-political-entry}

\subsubsection{ツールからエージェントへ}

AIの政治プロセスへの関与は、これまで主に「ツール」としての利用に限定されてきた。選挙予測モデル、世論調査の分析、政治広告のターゲティング、議事録の検索——これらはいずれも、人間のオペレータがAIを道具として操作するモデルである。

しかし、LLMの能力向上とエージェントフレームワークの発展により、AIは「ツール」から「エージェント」——すなわち、目標を与えられた上で自律的に情報を収集し、推論を行い、行動を実行する主体——へと変容しつつある。この変容は、政治プロセスへのAIの関与の質を根本的に変える。

\textcite{park2023generative}は、Generative Agentsの研究において、LLMに基づく25体のエージェントが仮想空間内で自律的に社会的行動——対話、協力、計画、パーティーの開催——を行うことを示した。このシミュレーションは、AIエージェントが社会的ダイナミクスを模倣し、さらには新たな社会的パターンを生成しうることを実証している。政治プロセスへの応用——例えば、市民の代理として政策討議に参加するエージェント、議会の議事をリアルタイムで分析・要約するエージェント、政策提案の影響を評価するエージェント——は、技術的には既に射程内にある。

\subsubsection{エージェントプロトコルの発展}

AIエージェントが実世界のシステムと相互作用するためのプロトコルは、2024--2025年に急速に発展している。

\begin{itemize}[nosep]
  \item \textbf{MCP（Model Context Protocol）}——Anthropicが2024年末に公開したオープンプロトコル。LLMがツール（API、データベース、ファイルシステム等）にアクセスするための標準化されたインターフェースを提供する。MCPサーバーを通じて、エージェントは外部データソースに構造化されたアクセスを行うことが可能になる。
  \item \textbf{A2A（Agent-to-Agent Protocol）}——Googleが2025年に提案したエージェント間通信プロトコル。異なるフレームワークで構築されたエージェント同士が、タスクの委任・結果の返却・状態の共有を行うための標準化されたプロトコルである。
  \item \textbf{OpenAI Agents SDK}——OpenAIが2025年にリリースしたエージェント構築フレームワーク。ツールの定義、マルチエージェントのオーケストレーション、ガードレールの設定を統合的に提供する。
  \item \textbf{LangGraph}——LangChainが開発したグラフベースのエージェントフレームワーク。状態を持つ循環的なワークフローを構築でき、複雑な推論タスクをエージェントに実行させることが可能。
\end{itemize}

これらのプロトコル・フレームワークの発展は、AIエージェントが外部システムと構造化された形で相互作用する能力を急速に拡大させている。政治データ基盤がこれらのプロトコルに対応していれば、エージェントは政治データへのアクセス、分析、報告を自律的に行うことが可能になる。逆に、政治データ基盤がエージェントの参入を前提としていなければ、エージェントは非構造的な手段（ウェブスクレイピング等）に依存せざるを得ず、データの正確性・網羅性が損なわれる。

\subsubsection{政治プロセスにおけるエージェントの想定される役割}

AIエージェントが政治プロセスに参入する場合、以下のような役割が想定される。

\begin{enumerate}[nosep]
  \item \textbf{政策モニタリングエージェント}——国会の議事、委員会の審議、政府の発表をリアルタイムで監視し、市民に関連する政策変更を通知する。
  \item \textbf{政策ブリーフィングエージェント}——複雑な政策課題について、市民が理解可能な要約・背景説明・論点整理を自動生成する。
  \item \textbf{熟議ファシリテーションエージェント}——オンライン熟議において、議論の要約、論点の整理、合意点の抽出を支援する。Habermas Machineの延長線上にある。
  \item \textbf{政治資金分析エージェント}——政治資金の流れを自動的に分析し、異常なパターンや利益相反の兆候を検知する。
  \item \textbf{市民代理エージェント}——市民の選好を学習し、特定の政策課題について市民の「代理」として意見表明を行う。これは最も論争的な応用であり、民主主義理論上の深刻な課題を提起する。
\end{enumerate}

これらの役割のうち、(1)--(4)は「支援的エージェント（supportive agents）」——人間の意思決定を補助するエージェント——であり、(5)は「代理的エージェント（proxy agents）」——人間に代わって意思表示を行うエージェント——である。本論文は、現時点では支援的エージェントの設計原則に焦点を当て、代理的エージェントの是非は今後の研究課題として位置づける。

% ----------------------------------------------------------------------------
\subsection{エージェントレディ設計の7原則}
\label{subsec:seven-principles}

以上の分析を踏まえ、エージェントレディな政治インフラの設計原則として以下の7原則を提案する。

\subsubsection{原則1: Open API Design——構造化された公開API}

\begin{quote}
\textit{すべての政治データソースに対して、構造化され、バージョン管理され、文書化されたAPIを提供する。}
\end{quote}

政治データ——国会議事録、政治資金報告書、選挙結果、法案テキスト、投票記録——は、民主主義のインフラストラクチャを構成する公共財である。これらのデータに対するプログラマティックなアクセスは、市民・研究者・ジャーナリスト・そしてAIエージェントにとって、政治プロセスの監視と参加の前提条件である。

APIの設計要件は以下の通りである。
\begin{itemize}[nosep]
  \item RESTful またはGraphQL による標準化されたエンドポイント
  \item セマンティックバージョニングによるAPI互換性の管理
  \item OpenAPI（Swagger）仕様による網羅的な文書化
  \item レート制限の合理的な設定（市民のアクセスを不当に制限しない）
  \item 認証の段階化（公開データは無認証、個人データは認証付き）
\end{itemize}

\subsubsection{原則2: Machine-Readable Data——機械可読データの標準化}

\begin{quote}
\textit{すべての政治データを、標準化された機械可読形式で提供する。}
\end{quote}

PDFや画像として公開されている政治データは、人間の目視には利用可能であっても、AIエージェントによる体系的な分析には適さない。JSON-LD、RDF、CSVなどの標準化された形式でのデータ提供が、エージェントレディ設計の基礎である。

特に重要なのは、政治データのリンクトデータ（Linked Data）化である。議員のIDが議事録・投票記録・政治資金報告書を横断的に紐付けられること、法案のIDが委員会審議・本会議採決・官報掲載を一貫して追跡できること——これらのデータ間の相互参照が機械可読な形で実現されていることが、エージェントによる高度な分析の前提条件となる。

\subsubsection{原則3: Audit Trail——完全な監査証跡}

\begin{quote}
\textit{AIエージェントのすべての行動を記録し、事後的に検証可能な監査証跡を維持する。}
\end{quote}

AIエージェントが政治プロセスに参入する場合、そのエージェントが「何を」「いつ」「なぜ」行ったかを完全に記録し、事後的に検証可能にすることが不可欠である。これは、民主主義プロセスにおける説明責任（accountability）の要件から導かれる。

監査証跡に記録すべき情報は以下の通りである。
\begin{itemize}[nosep]
  \item エージェントの識別子（どのエージェントが行動したか）
  \item 行動のタイムスタンプ（いつ行動したか）
  \item 行動の内容（何を行ったか——データアクセス、分析、出力の生成等）
  \item 行動の根拠（なぜ行ったか——どの指示に基づくか、どのモデルを使用したか）
  \item 入力データ（どのデータを参照したか）
  \item 出力データ（どのような結果を生成したか）
\end{itemize}

\subsubsection{原則4: Human-in-the-Loop——人間による最終判断}

\begin{quote}
\textit{AIエージェントは提案を行い、人間が最終判断を下す。}
\end{quote}

エージェントレディ設計は、AIエージェントの自律性の拡大を目指すものではなく、AIエージェントが人間の意思決定を支援するための基盤の整備を目指すものである。「AI proposes, humans dispose（AIが提案し、人間が決定する）」の原則は、エージェントレディ設計の中核をなす。

この原則の具体的な実装は以下の通りである。
\begin{itemize}[nosep]
  \item エージェントの出力には必ず「AIによる生成」のラベルを付与する
  \item 政策的判断を伴う出力（政策提言、合意文案等）には人間の承認プロセスを設ける
  \item エージェントの行動範囲を明示的に制限し、予期しない行動を防止する
  \item 人間がエージェントの行動をいつでも中断・修正できるインターフェースを提供する
\end{itemize}

\subsubsection{原則5: Bias Detection——偏向の継続的検出}

\begin{quote}
\textit{AIエージェントの出力における党派的偏向を継続的に監視・検出する。}
\end{quote}

\textcite{stanfordhai2025aiindex}が報告するように、主要なLLMは体系的な政治的偏向を内包している。\politech{}プラットフォームにおいてAIエージェントを活用する場合、その出力における偏向の検出と修正のための仕組みが不可欠である。

偏向検出の手法は以下の通りである。
\begin{itemize}[nosep]
  \item 同一の政策課題について、複数のLLMの出力を比較し、体系的な偏向パターンを検出する
  \item エージェントの出力を、人手によるアノテーションと照合して偏向を定量化する
  \item 政策課題の左右軸・保革軸における出力の分布を定期的に監視する
  \item 偏向が検出された場合のフォールバック手順（人間による確認、代替モデルの使用等）を定義する
\end{itemize}

\subsubsection{原則6: Interoperability——相互運用性}

\begin{quote}
\textit{特定のエージェントフレームワークやプロトコルに依存しない、相互運用可能な設計を採用する。}
\end{quote}

エージェントプロトコルの発展は急速であり、MCP・A2A・OpenAI Agents SDK・LangGraphなど、複数のフレームワークが並立している。\politech{}プラットフォームが特定のフレームワークに依存する場合、技術的ロックインのリスクが生じる。

相互運用性の確保のための設計方針は以下の通りである。
\begin{itemize}[nosep]
  \item 標準的なHTTP/REST/GraphQL APIを基盤層として提供し、その上に各プロトコルのアダプターを実装する
  \item MCP Serverとしてのインターフェースを提供しつつ、MCPに依存しない直接APIアクセスも可能にする
  \item データ形式はJSON-LD等の標準仕様に準拠し、フレームワーク固有の形式に依存しない
  \item エージェント認証は、OAuth 2.0等の標準的な認証プロトコルに基づく
\end{itemize}

\subsubsection{原則7: Transparency——透明性}

\begin{quote}
\textit{政治プロセスで使用されるすべてのAIモデルは、オープンウェイトまたは少なくとも監査可能でなければならない。}
\end{quote}

プロプライエタリなAIモデルが政治プロセスの中核で使用される場合、モデルの偏向・挙動・限界を外部から検証することが不可能となり、民主主義的正統性が構造的に損なわれる。

\begin{proposition}
政治の意思決定プロセスにおいて使用されるAIモデルが外部から検証不可能であることは、当該プロセスの民主主義的正統性を毀損する。したがって、\politech{}プラットフォームで使用されるAIモデルは、オープンウェイト（open-weight）——すなわちモデルの重みが公開されている——であるか、少なくとも独立した第三者による監査が可能（auditable）でなければならない。
\end{proposition}

この命題の論証は以下の通りである。民主主義の正統性は、意思決定プロセスの透明性と検証可能性に依存する\autocite{landemore2020open}。プロプライエタリなAIモデルは、そのアーキテクチャ・学習データ・推論過程が非公開であり、出力に内包される偏向を独立に検証することが不可能である。意思決定プロセスの一部が検証不可能なブラックボックスによって担われている場合、当該プロセスの出力は——たとえ結果的に公正であったとしても——民主主義的正統性を主張することができない。なぜなら、「正しい結果が偶然にもたらされた」ことと、「正しいプロセスから正当な結果が導出された」ことは、民主主義理論において質的に異なるからである。

% ----------------------------------------------------------------------------
\subsection{OJPPにおけるエージェントレディ実装}
\label{subsec:ojpp-agent-ready}

上述の7原則に基づき、OJPPにおけるエージェントレディ設計の実装方針を示す。

\subsubsection{API設計}

OJPPは、すべてのサービス（MoneyGlass、ParliScope、PolicyDiff、SeatMap）に対して、以下の仕様に基づくAPIを提供する。

\begin{itemize}[nosep]
  \item \textbf{RESTful API}——各サービスのデータに対するCRUD操作を標準的なHTTPメソッドで提供。OpenAPI 3.0仕様に基づく文書化。
  \item \textbf{GraphQL API}——複数のデータソースにまたがる複合的なクエリに対応。議員のID→発言記録→投票記録→政治資金、のようなデータの横断的取得を単一のクエリで実現。
  \item \textbf{MCP Server}——OJPPの全APIをModel Context Protocolのサーバーとして公開し、LLMエージェントがOJPPのデータにツールとしてアクセス可能にする。
  \item \textbf{Webhook}——政治資金報告書の更新、国会会期の開始・終了、重要法案の採決など、政治イベントの発生をリアルタイムでエージェントに通知する。
\end{itemize}

\subsubsection{エージェント活用の想定シナリオ}

OJPPのAPI基盤上で、以下のようなエージェント活用シナリオが想定される。

\paragraph{シナリオ1: 国会モニタリングエージェント}
ParliScope APIを用いて国会の審議をリアルタイムで監視し、特定の政策分野に関連する発言・質疑・採決をフィルタリングして市民に通知するエージェント。例えば、「教育政策」に関心のある市民が、教育関連の国会審議の要約を毎日受け取ることが可能になる。

\paragraph{シナリオ2: 政治資金分析エージェント}
MoneyGlass APIを用いて政治資金の流れを分析し、異常なパターン——特定の業界団体からの献金の急増、政策決定と献金時期の相関——を検出するエージェント。ジャーナリストの調査報道や市民の監視活動を支援する。

\paragraph{シナリオ3: 政策比較エージェント}
PolicyDiff APIを用いて、選挙時に各政党の政策を市民の関心事項に基づいて比較し、分かりやすい比較レポートを生成するエージェント。従来は専門家やメディアが担っていた政策比較の機能を、AIエージェントが補完する。

\subsubsection{将来展望}

OJPPのエージェントレディ設計は、現時点では「支援的エージェント」の基盤整備に焦点を当てている。将来的には、以下の展開が想定される。

\begin{itemize}[nosep]
  \item \textbf{熟議ファシリテーション}——Decidim等の熟議プラットフォームとOJPPを連携し、AIエージェントが議論の要約・論点整理・合意点抽出を行う熟議支援システムの構築。
  \item \textbf{マルチエージェント政策シミュレーション}——Park et al.のGenerative Agentsの手法を応用し、多様な市民の立場を模擬するエージェントによる政策影響のシミュレーション。
  \item \textbf{国際的なエージェント間連携}——A2Aプロトコルを用いて、日本のOJPPと台湾のvTaiwan、欧州のDecidim等のプラットフォーム上のエージェントが、国際比較分析を自律的に行う協調システム。
\end{itemize}

% ----------------------------------------------------------------------------
\subsection{検証可能性とオープンソース要件}
\label{subsec:verifiability}

本節の最後に、プロプライエタリなAIを政治プロセスに組み込むことの構造的危険性について、形式的な論証を試みる。

\begin{theorem}[検証不可能性の正統性毀損定理]
\label{thm:verifiability}
政治の意思決定プロセス $P$ において、決定関数 $f$ の一部がブラックボックスモジュール $B$（外部から検証不可能なモジュール）によって構成されている場合、$P$ の民主主義的正統性は構造的に毀損される。
\end{theorem}

\begin{proof}[論証の概略]
民主主義的正統性は、\textcite{habermas1996between}によれば、意思決定プロセスが以下の条件を満たすことを要件とする。(i) 影響を受けるすべての人がプロセスに参加可能であること、(ii) プロセスが理由づけ（reason-giving）に基づくこと、(iii) プロセスが反省的に検証可能であること。

ブラックボックスモジュール $B$ は、条件 (iii) を構造的に不充足にする。$B$ の入出力関係は観測可能であっても、$B$ 内部の推論過程——どのような理由づけに基づいて出力が導出されたか——は外部から検証できない。したがって、$B$ を含む決定関数 $f$ は、条件 (ii) と (iii) を同時に満たすことができず、$P$ の民主主義的正統性は毀損される。

よって、政治の意思決定プロセスにおいて使用されるAIモデルがオープンウェイトまたは監査可能であることは、民主主義的正統性の必要条件（十分条件ではない）である。
\end{proof}

この定理は、オープンソースが\politech{}における「あればよい（nice-to-have）」特性ではなく、「なくてはならない（must-have）」構造的要件であることを論証するものである。オープンソースは、民主主義的正統性の確保のための必要条件——十分条件ではないが、なければ正統性が成立しない条件——である。
